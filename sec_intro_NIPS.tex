% !TEX root = main_nips.tex
We consider the fast computation of constrained shortest paths in large-scale graphs, using preprocessing and graph augmentation techniques.
The Shortest-path (SP) problem is one of the canonical algorithm design problems.
In recent years, however, it has been revolutionized both in terms of academic research as well as real-world applications (cf.~\cite{goldberg_survey,dimacs09} for surveys).
In particular, the use of preprocessing techniques and network augmentation has led to dramatic improvements in the speed and scalability of SP computation in road networks.
These techniques however do not extend to constrained shortest-path (CSP) problems, and our work aims to bridge this gap.

The SP and CSP problems can be summarized as follows: We are given a graph $G$, where each edge has an associated \emph{length} and \emph{cost}. 
Now, given any two nodes $s,t$, the SP problem requires finding an  $s\rightarrow t$ path of minimum length; the CSP problem takes in a further input of a budget $b$, and requires finding a minimum length $s\rightarrow t$ path \emph{which moreover has a total cost less than $b$}.
The two problems, though similar, have very different basic complexity: SP computation admits a polynomial-time algorithm (in particular, the famous Dijkstra's algorithm), while the problem of CSP computation is known to be NP-Hard~\cite{csp_survey}.
That said, a standard dynamic programming approach allows CSP computation in pseudo-polynomial time when the costs are discrete (in particular, polynomial in the maximum budget), and also admits a natural scaling-based FPTAS for continuous costs (akin to the knapsack FPTAS).

Although there is a rich literature on CSP problems (cf. \cite{csp_survey} for a survey), there is little work on studying ways of using preprocessing and graph augmentation to speed up CSP computation. Our work here aims to address this gap, motivated by the success of similar approaches for SP computation. Moreover, we believe that there is a need for such techniques in several modern applications, as we discuss next. 


\paragraph*{Applications of large-scale CSP computation}

Our interest in CSP computation is motivated primarily by the requirements of transportation platforms like Lyft, Uber, Waze etc., for accurate routing and travel-time estimates with probabilistic guarantees.
Fast routing and trip-time estimation, driven by fast SP engines (for example, OSRM~\cite{OSRM}), have provided impetus to the increasing use of mobile maps.
These techniques however do not make full use of available real-time traffic information; in particular, SP queries are unable to incorporate uncertainties in travel times, and hence often give inaccurate trip-time estimates in settings with high traffic uncertainty.


A natural way to incorporate travel-time uncertainty is to compute the shortest path subject to a reliability constraint.
In particular, in many settings, we want \emph{robust} travel time estimates: formally, we require that given $s,t$ and parameters $p,\delta$, a routing algorithm returns an $(s,t)$-path $P$ minimizing $\E[\ell(P)]$, subject to $\Pr[\ell(P)>\E[\ell(P)]+\delta]\leq p$.
Even assuming that travel times on different road segments are independent, computing this exactly for general distributions is expensive due to the need for computing convolutions of distributions. However, for uncorrelated travel-times, we have $\Pr[\sum_eT_e>\E[\sum_eT_e])+\delta]\leq \sum_e\Var(T_e)/\delta^2$ by Chebyshev's inequality; using this, we can replace the robust trip-time estimation problem with the following
\begin{center}
$\min_{ P\in\Pst}\sum_{i\in P}\mu_i \qquad \mbox{s.t.}\qquad \sum_{i\in P}\sigma^2_i\leq \delta^2p.$
\end{center}
This is now a CSP problem. Note that the solution, though not necessarily optimal, always respects the reliability constraint -- this is often more critical for practical applications.


Another problem that can be modeled as a CSP is that of finding \emph{reliable shortest paths}.
Consider the case where each edge has a probability $q_e$ of triggering a bad event, with resulting penalty $p$ (for example, slowdowns due to accidents).
In this case, we want to minimize the travel time as well as the expected penalty.
In this case, assuming independence, we have the following natural problem
\begin{center}
$\min_{P\in\Pst} \ell(P)+p\prn*{1-\prod_{e\in P}(1-q_e)}.$
\end{center}
This model is considered in \cite{fareevasion} (for routing with fare evasion, where $q_e$ is the probability of encountering an inspector, and $p$ the penalty), where the authors suggest using a CSP formulation, wherein the non-linear objective is replaced by a linear constraint by taking logarithms.

%Finally, another class of problems which is related to the CSP is that of routing under \emph{label constraints} \cite{language_csp,rice_csp}, wherein we want shortest routes which satisfy certain properties (for example, those that avoid toll roads). The main idea in such problems (as in the CSP) is to use an appropriate augmented graph that converts feasible shortest paths to shortest paths. Our results extend to these applications as well.

\subsection{Our Contributions}

\noindent We aim to address the following overarching questions:
\begin{enumerate}[nosep,leftmargin=*]
\item How can we use preprocessing and graph augmentation techniques to speed up CSP computation. 
\item How can we give preprocessing/storage/query time guarantees for such techniques.
\end{enumerate}

For the SP problem, there was significant initial development on the first question, leading to many different techniques~\cite{dimacs09}, which worked well in practice, but had no performance guarantees.
Abraham et al.~\cite{highway2013, highway2010} then proposed the \emph{Highway Dimension} (HD), a graph structural metric, which they showed could parametrize the preprocessing, storage and query time of several of these heuristics (hub labels, contraction hierarchies, etc.).
Our work adopts a similar program; in particular, our contributions are as follows:
\begin{itemize}[nosep,leftmargin=*]
\item \textbf{Theoretical contributions}: 
We extend the HD to directed graphs and general path systems (Section~\ref{ssec:hddef}), and define an analogous notion of a \emph{constrained highway dimension} (CHD) for Pareto efficient paths (Section~\ref{sec:chd}). We then construct an augmented graph (Section~\ref{ssec:aug}) under which efficient paths are mapped to shortest paths, and use it to develop hub labels for CSP queries, whose complexity is parameterized by the CHD (Section~\ref{ssec:hlcsp}).
Finally, we show that although the CHD can be much bigger than the HD in general, the two can be related under an additional \emph{partial witness condition} (Section~\ref{ssec:hdvschd}). This provides some justification for the use of preprocessing techniques for CSP, as it suggests that they should work well in settings where SP computation admits good speedup techniques.
\item \textbf{Practical contributions}: Although the theoretical results justify the use of preprocessing techniques for CSP, they are impractical for real networks. We show how we can adapt our theoretical ideas to develop a practical construction technique for hub labels that support CSP queries (Section~\ref{sec:numeric}). We then evaluate our algorithm on datasets with detailed travel-time information for San Francisco and Luxembourg (Section~\ref{sec:exp}). Our experiments show that our hub labels support query times which are orders of magnitude faster than existing techniques (without preprocessing), have small per-node storage requirements, and good preprocessing times even on a single machine. 
\end{itemize}	

\subsection{Related work}

As we mention before, our work is inspired by the recent developments (both theoretical and practical) in shortest path algorithms~\cite{highway2013,hubimplem,highway2010,dimacs09,geisberger_ch_definition,skeleton}; refer~\cite{goldberg_survey} for an excellent survey of these developments. 


The problem of finding robust shortest paths is closely related to the stochastic on-time arrival (SOTA) problem~\cite{fan2005arriving}.
The SOTA problem with Gaussian travel times was solved via exhaustive search~\cite{nikolova_gaussian}. The optimal policy under discrete distributions was given in~\cite{samaranayake2012speedup}, and pre-processing policies were considered in~\cite{sabran2014precomputation}. Finally, ~\cite{nikolova_discretization} provides an approximation technique based on discretization for DAGs.

The primary speedup technique we use in our work is that of hub labels (HL). This was introduced first in~\cite{cohen_definition_hl}. More recently, HL was shown to admit the best query time bounds in low HD graphs~\cite{highway2013,highway2010}, and this observation was experimentally confirmed in~\cite{hubimplem} (see also Figure 7 in~\cite{goldberg_survey}).  
Finally, the HD-based bounds for hub labels was shown to be tight in~\cite{babenko_hl_complexity,white_complexity_hd}, and it was also shown that finding optimal hub labels is NP hard.

There is an extensive literature on CSP problems, which is well surveyed in~\cite{csp_survey}; most of this work however considers only query-time techniques without preprocessing. Our graph augmentation technique is similar to that proposed in~\cite{alex_bicriteria}, which is based on a dynamic programming approach. 

Finally, a related class of problems to CSP is that of shortest paths under label constraints, first introduced in~\cite{language_csp}. Contraction hierarchies were adapted to solve a restricted class of such problems in~\cite{rice_csp}, where the aim was to find shortest paths that avoided certain labels (for example, toll roads/ferries). Our work is similar in spirit to this paper. Note however that the label-constrained problem in~\cite{rice_csp} is a concatenation of parallel shortest-path problems, and involves only local constraints. 
In contrast, the CSP is NP-hard as it involves global constraints on paths; consequently, a small number of edges with costs can affect all nodes. Thus, though the techniques in~\cite{rice_csp} do not apply to our setting, our theoretical results do in fact shed light on why contraction hierarchies work well in their setting.