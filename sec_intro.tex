Motivated by the requirements of modern transportation systems, we consider the fast computation of constrained shortest paths (CSP) in large-scale graphs. Though the basic shortest-path (SP) problem has a long history, it has been revolutionized by recent algorithmic advancements that help enable large-scale mapping applications (cf.~\cite{goldberg_survey,dimacs09} for surveys).
In particular, the use of preprocessing techniques and network augmentation has led to dramatic improvements in the scalability of SP computation for road networks.
These techniques however do not extend to the CSP.
%, and hence can not fully leverage the rich travel-time distribution data available today.

The SP and CSP problems can be summarized as follows: Given a graph $G$ where each edge has associated \emph{length} and \emph{cost}, the SP problem requires finding an $(s,t)$-path of minimum length for any given nodes $s$ and $t$. 
The CSP problem inputs an additional budget $b$, and requires finding a minimum length $(s,t)$-path \emph{with total cost less than $b$}.
The two problems, though similar, have very different runtime complexity: SP queries admit polynomial-time algorithms (in particular, the famous Dijkstra's algorithm), while CSP computation is known to be NP-Hard~\cite{csp_survey}.
That said, a standard dynamic programming computes CSPs in pseudo-polynomial time for discrete costs, and gives a natural scaling-based FPTAS for continuous costs (as in the knapsack problem).

Though there is a rich literature on CSP (cf. \cite{csp_survey}), existing approaches do not scale to support modern applications. 
To this end, we study \emph{preprocessing and network augmentation for speeding CSP computation}.
Our work contributes to a growing field of algorithms for large-scale problems (non-convex methods, sketching techniques, etc.), with poor worst-case performance, but which are provably efficient for practically relevant settings.

\smallskip
\noindent\textbf{Applications of large-scale CSP computation:}
Our primary motivation for scaling CSP comes from the requirements of modern transportation platforms (Lyft, Uber, Waze etc.) for accurate routing and travel-time estimates.
%\anote{Maybe use tolls or physical costs as primary motivation? Reviewers got really fixed on the independence thing}
Modern SP engines like Google Maps and OSRM do not make full use of available traffic information.
In particular, they do not incorporate uncertainties in travel times, leading to inaccurate estimates in settings with high traffic variability.
This can be corrected by computing shortest paths based on \emph{robust} travel-time estimates:
given $s,t$ and parameters $p,\delta$, we want to find an $(s,t)$-path $P$ minimizing $\E[\ell(P)]$, subject to $\Pr(\ell(P)>\E[\ell(P)]+\delta)\leq p$.
Computing this exactly for general distributions is expensive due to the need for computing convolutions of distributions. 
However, assuming uncorrelated travel-times across different road segments (\sbedit{Comment on conditional independence - cite Dawn}), 
%\anote{some citations here to justify independence} 
Chebyshev's inequality gives us that $\Pr(\sum_eT_e>\E[\sum_eT_e]+\delta)\leq \sum_e\Var(T_e)/\delta^2$. Using this, we can reformulate the robust trip-time estimation problem as 
$\min_{ P\in\Pst}\sum_{i\in P}\mu_i \, \mbox{s.t.}\, \sum_{i\in P}\sigma^2_i\leq \delta^2p$, which is now a CSP problem. 
Note that though we relax the condition $\Pr(\ell(P)>\E[\ell(P)]+\delta)\leq p$, our solution always respects this constraint -- this is often more critical for practical applications, e.g., for ETA estimates accuracy is more important than optimality.

Another problem that can be modeled as a CSP is that of finding \emph{reliable shortest paths}.
Consider the case where each edge has a probability $q_e$ of triggering a bad event, with resulting penalty $p$ (for example, slowdowns due to accidents).
In this case, we want to minimize the travel time as well as the expected penalty.
Assuming independence, we have the following natural problem:
$\min_{P\in\Pst} \ell(P)+p\prn*{1-\prod_{e\in P}(1-q_e)}$.
This model is considered in \cite{fareevasion} for routing with fare evasion, where $q_e$ is the probability of encountering an inspector, and $p$ the penalty; the authors suggest using a CSP formulation, wherein the non-linear objective is replaced by a linear constraint by taking logarithms.

%Finally, another class of problems which is related to the CSP is that of routing under \emph{label constraints} \cite{language_csp,rice_csp}, wherein we want shortest routes which satisfy certain properties (for example, those that avoid toll roads). The main idea in such problems (as in the CSP) is to use an appropriate augmented graph that converts feasible shortest paths to shortest paths. Our results extend to these applications as well.

\paragraph{Our Contributions}
We consider the problem of computing constrained shortest paths on large networks, with fixed-sized budgets and integer edge-costs. For fixed source and destination, the CSP admits a natural dynamic-programming algorithm; our focus however is on developing data-structures that support arbitrary source-destination-budget queries. In particular, our work addresses the following questions:\\
\noindent $1.$ How can we use preprocessing and network augmentation techniques to speed up CSP computation? \\
\noindent $2.$ How do we obtain preprocessing/storage/query time guarantees for such techniques?

For the SP problem, there were several known heuristics which worked well in practice~\cite{dimacs09}, but had no performance guarantees.
These were unified by Abraham et al.~\cite{highway2013, highway2010} via the \emph{Highway Dimension} (HD), a graph structural metric, which they showed could parametrize the preprocessing, storage and query time of these heuristics.
Our work adopts a similar program for the CSP; in particular, our contributions are summarized as follows:

\noindent\textbf{Theoretical contributions}: 
Analogous to the role of the Highway Dimension for the set of shortest paths, we define the \emph{constrained highway dimension} (CHD) for set of {\em efficient paths} (i.e., minimal solutions to the CSP; cf. \ref{def:effpath}). We show how the CHD can be used to parametrize the performance of CSP algorithms via a reduction from a CSP problem to an SP problem on an appropriate \emph{augmented graph}, a directed graph that jointly encodes the cost and length constraints. The problem however is that the CHD can be much bigger than the HD in general -- our main theoretical contribution is in showing that the \emph{HD and CHD an be related under an additional partial witness condition}. 
This provides a justification for our proposed CSP algorithms, as it shows they are efficient in settings where SP computation is scalable. We also study the  average performance and obtain stronger results. 
In particular, we show how a small average CHD can be explained by physical overpasses in road networks.

\noindent\textbf{Practical contributions}: 
Although our theoretical results justify the use of hub labels for CSP, they are impractical for real networks. 
In \cref{sec:numeric}, we show how to adapt our ideas to develop practical hub label constructions for CSP queries. 
We evaluate our algorithm on datasets with detailed travel-time information for San Francisco and Luxembourg.
Our experiments show that our hub labels support query times which are orders of magnitude faster than existing techniques (without preprocessing), have small storage requirements, and good preprocessing times even on a single machine. 

\noindent\textbf{Paper outline}:
In \cref{sec:prelim}, after introducing the problem, we extend the notion of the HD (as defined in \cite{highway2013}) to directed graphs and general path systems. Then, in \cref{sec:chd}, we define an analogous notion of a \emph{constrained highway dimension} (CHD) for constrained shortest paths. 
We then propose a construction of hub labels for CSP queries, whose complexity is parameterized by the CHD. 
We show that, although the CHD can be much bigger than the HD in general, the two can be related under an additional \emph{partial witness condition}. 
This provides a justification for our proposed CSP hub labels, as it suggests that they should be efficient in settings where SP computation is scalable.
Finally, we study average performance and obtain stronger results. 
In particular, we show how a small average CHD can be explained by physical overpasses in road networks.


\noindent\textbf{Related work}:
CSP problems have an extensive literature, surveyed in~\cite{csp_survey}. 
More recently, there has been significant interest in robust SP problems, as well as the related stochastic on-time arrival (SOTA) problem~\cite{fan2005arriving}; recent works have proposed both optimal and approximate policies~\cite{sabran2014precomputation,nikolova_discretization}. 
Existing approaches for these problems, however, do not exploit preprocessing and augmentation techniques, and consequently do not support the latencies required for mapping applications.
%The SOTA problem with Gaussian travel times was solved via exhaustive search~\cite{nikolova_gaussian}. 
%The optimal policy under discrete distributions was given in~\cite{samaranayake2012speedup}, and pre-processing policies were considered in~\cite{sabran2014precomputation}. 
%Finally, ~\cite{nikolova_discretization} provides an approximation technique based on discretization for DAGs.

As we mention before, our work is inspired by the recent developments in shortest path algorithms~\cite{highway2013,hubimplem,highway2010,dimacs09,geisberger_ch_definition,skeleton}; refer~\cite{goldberg_survey} for an excellent survey of these developments. 
%Our graph augmentation technique is similar to that proposed in~\cite{alex_bicriteria}, which is based on a dynamic programming approach. 
The pre-processing technique we use for speeding CSP computations is hub labels (HL), first introduced for SP computations in~\cite{cohen_definition_hl}. 
More recently, HL was proved to have the best query-time bounds for SP computation in low HD graphs~\cite{highway2013,highway2010} (this was experimentally confirmed in~\cite{hubimplem}, \cite[Figure 7]{goldberg_survey}).  
Finally, the HD-based bounds for hub labels was shown to be tight in~\cite{babenko_hl_complexity,white_complexity_hd}, and it was also shown that finding optimal hub labels is NP hard.

Finally, a related class of problems to CSP is that of shortest paths under label constraints~\cite{language_csp}, where the aim is to find shortest paths that avoided certain labels (e.g. toll roads, ferries, etc.). \cite{rice_csp} proposed preprocessing techniques (in particular, contraction hierarchies) for restricted class of such problems. 
Note however that label-constrained SP problem is essentially a concatenation of parallel SP problems, and involves only local constraints; in contrast, the CSP involves global constraints on paths, and consequently is known to be NP-hard. 
Moreover, our results do in fact shed light on why contraction hierarchies work well for label-constrained SP queries.