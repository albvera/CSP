% !TEX root = main_vldb.tex
\subsection{Practical algorithm}
The augmented graph defined in section \ref{sec:augmented} may contain a lot of redundant information relative to the minimal representation.
For example, the same efficient path $uv$ can be repeated many times in the form $\pp{u,1}\pp{v,0}$, $\pp{u,2}\pp{v,1}$ and so on.
By encoding this information more efficiently, we can reduce the size of the augmented graph and obtain considerable improvements both in query time and in data storage.

We can construct an augmented graph without this duplicated information as follows.
The nodes are, as before, pairs $\pp{v,b}$, but an edge $(\pp{v,b},\pp{v',b'})$ is placed only if the minimal set of efficient paths uses it.
If we let $\calP_{s,t}^E$ be the set of all efficient paths from $s$ to $t$, we take every $P\in \calP_{s,t}^E$ with cost $b\leq B$ and trace it in the augmented graph only if it ends at $\pp{t,0}$. In other words, all efficient paths $P\in \calP_{s,t}^E$ can be represented by a set a set of efficient paths ending at $\pp{t,0}$. 

\begin{definition}
The pruned augmented graph is defined by $\Gp^B=(\Vp^B,\Ep^B)$, where
\begin{align*}
\Vp^B &:=\{\pp{v,b}: v\in V, b=0,1,\ldots,B\},\\
\Ep^B &:=\{\pp{v,b}\pp{v',b'} : \exists s,t\in V, P\in\calP^E_{s,t}, c(P)\leq B, \\
&\qquad vv'\in P, b=c(P[v,t]), b'=c(P[v',t])  \}.
\end{align*}
In $\Gp^B$ all the lengths are preserved.
\label{def:pruned_aug_graph}
\end{definition}
Note that in $\Gp^B$ there are no sink nodes, hence it has at least $n$ nodes and $nB$ arcs fewer compared to $G^B$.

\subsubsection{HD of the pruned augmented graph}

A shortest path in $\Gp$ does not necessarily project to an efficient path, even if the path ends in a node of the form $\pp{t,0}$.
On the other hand, if $P$ projects to an efficient path, then necessarily $P$ is shortest. 
To bound the HD, the correct system to study is
\[
\tilde\calP^B:=\{P: P\text{ ends in a node }\pp{t,0}, \bar P\in \PE, c(\bar P)\leq B \}.
\]
The following result shows how the HD of this system relates to that of $\PE$.
We omit the proof since it is identical as the one in Proposition~\ref{prop:HDaugmented}.
\begin{proposition}
The HD of $\tilde\calP^B$ is $Bh_c$, where $h_c$ is the HD of $\PE$.
\end{proposition}

We use techniques described in \cite{hubimplem} combined with an approach tailored for augmented graphs.
The main idea is to first use contraction hierarchies to get a node ranking and then define the forward hubs of a node as the nodes visited during a contraction-based forward search.
The backward hub is defined analogously.
These are valid hubs, since the highest rank node in a path is guaranteed to be in both hubs.

The most important parameter in CH is the rank; results vary greatly from one choice of ranks to another.
We obtain a rank in $G$ by running a greedy shortest-path cover, defined as follows.
Start with a cover $C=\varnothing$ and compute the set of all shortest paths $\calP$.
Take a node $v\notin C$ hitting most paths in $\calP$, then remove all those paths from $\calP$, add $v$ to $C$ and iterate.
The rank is defined as $n$ for the first node added to $C$, $n-1$ for the second and so on.

We work with the pruned augmented graph, i.e.\ $\tilde G_B$, which takes some time to compute, but yields considerably better hubs. 
Recall that in $\tilde G_B$ there are no sink-nodes nor ``replicated information'', since efficient paths are stored just once.
Given a rank for nodes in $G$, we contract $\tilde G_B$ as follows.
Say that $V$ is ordered according to the rank, so node $1$ is the least important and $n$ the most important.
In $\tilde G_B$, for $b=B,\ldots,0$, we contract the nodes $(1,b)$ first, then the nodes $(2,b)$ and so on till the nodes $(n,b)$ are the last to contract. 

To obtain better hubs we prune the results obtained by contraction-based searches.
If $w$ is in the forward search of $v$ with distance $d$, it might be that $\dist(v,w)<d$, this occurs because the search goes only to higher rank nodes and the discovered path is missing some node.
When $\dist(v,w)<d$, we can safely remove $w$ from the hub of $v$, since the highest ranked node in a shortest path will have the correct distance.
We describe now the process in the following steps.

\begin{enumerate}[nosep]
\item Compute the shortest paths in $G$ and obtain a cover $C$
\item Compute the pruned augmented graph $\tilde G_B$
\item Contract $\tilde G_B$ using the rank given by $C$
\item Create hubs $\Lf(v),\Lb(v)$ using CH
\item Prune the hubs by running HL queries between $v$ and nodes in $\Lf(v)$. 
Run a similar process for $\Lb(v)$.
\end{enumerate}
Note that in the last step we bootstrap HL to improve it.
This works because the fact that some nodes have incorrect distance labels does not impact the correctness of a HL query; a node minimizing the distance is returned and such node must have a correct label.

\subsection{Experiments}

All the experiments were performed on a 64-bit desktop computer with a 3.40GHz Intel Core i7-6700 processor and 16GB RAM running Ubuntu 16.04.
The entire code is written in Python 2.7. We use the library Networkx for the graph representation and Dijkstra's algorithm.
To compute the SP cover we follow the exhibition in \cite{hubimplem}.

We evaluated the performance of our algorithms with real-world test networks: a small San Francisco network with 2643 nodes and 6588 edges for which real-world travel-time data was available as a Gaussian mixture model \cite{sf_data}, and a second (slightly larger) Luxembourg City network with 4026 nodes and 9282 edges for which travel-time distributions were synthesized from road speed limits \cite{niknami2016tractable}, as real-world data was unavailable.
 
In our experiments, we use the mean travel times for our length function and the following cost structure. The 10\% edges with the highest variance are assigned cost 1 and the rest cost 0.

\subsubsection{Runtime performance}


Tables~\ref{tab:sf_results} and \ref{tab:lu4k_results} present the CSP computation times for different maximum budgets $B$. The query times are measured as the average of 1000 random $s,t$ pairs, were the task is to recover $\dist(s,t|b)$ for every $b=0,1,\ldots,B$, i.e., the entire efficient frontier.  The column for $B=0$ represents the original graph (without augmentation). For each maximum budget level $B$, we consider compare two cases: i) $B-f$ that computes the entire solution frontier for all budgets $b\leq B$ on a fully pruned graph (as given in Definition~\ref{def:pruned_aug_graph}, and ii) $B-s$ that computes the solution only for the specified budget level on the fully pruned graph with XXX (\todo{Alberto to connect with previous section}). As can be seen in the experimental results, our method finds the constrained shortest path solution on average four orders of magnitude faster than running Dijkstra's algorithm on the augmented graph. Finding the solution frontier takes longer, but results in a more compact set of hub labels since at each budget level the problem only needs to consider paths that ... \todo{needs to be completed}. 

\begin{table*}
\begin{subtable}{.5\textwidth}
\begin{center}
\begin{tabular}{ | l | p{1cm} | p{1cm} | p{1cm} | p{1.2cm} | p{1.2cm} | }
\hline
	B & Preproc [m] & Avg F Size & Avg B Size & Query Dij [ms] & Query HL [ms] \\ \hline \hline
	0 & 0 & 0 & 0 & 0 & 0.000 \\ \hline
5-f  & 5  & 17 & 28 & 74.71  & 0.02  \\
5-s  & 5  & 57 & 28 & 32.67  & 0.009 \\\hline
10-f & 13 & 17 & 28 & 183.18 & 0.03  \\
10-s & 10 & 68 & 28 & 56.56  & 0.01  \\\hline
15-f & 14 & 17 & 28 & 250    & 0.03  \\
15-s & 15 & 73 & 28 & 81.48  & 0.01  \\\hline
20-f & 21 & 17 & 28 & 489.74 & 0.04  \\
20-s & 21 & 77 & 28 & 103.72 & 0.01  \\\hline
25-f & 22 & 17 & 28 & 467.84 & 0.04  \\
25-s & 24 & 80 & 28 & 122.57 & 0.01  \\\hline
30-f & 37 & 17 & 28 & 648.17 & 0.04  \\
30-s & 32 & 84 & 28 & 161.99 & 0.01  \\\hline
\end{tabular}
\caption{San Francisco network.}\label{tab:sf_results}
\end{center}
\end{subtable}
\begin{subtable}{.5\textwidth}
\begin{center}
\begin{tabular}{ | l | p{1cm} | p{1cm} | p{1cm} | p{1.2cm} | p{1.2cm} |}
\hline
	B & Preproc  [m] & Avg F Size & Avg B Size & Query Dij [ms] & Query HL [ms] \\ \hline \hline
	0 & 6 & 18 & 18 & 16.35 & 0.004 \\ \hline
	5-f & 23 & 14& 19 & 151.91 & 0.019 \\ 
	5-p & 21 & 43 &19 & 72.03 & 0.008 \\ \hline
	10-f & 36 & 14 & 19 & 305.33 & 0.021 \\ 
10-p & 35 & 49 & 19 & 102.52 & 0.008 \\ \hline
	15v & 51 & 14& 19 & 490.75 & 0.024 \\ 
	15-p & 46 & 53 & 19 & 140.80 & 0.008 \\ \hline
	20-f & 69 & 14 & 19 & 808.90 & 0.030 \\ 
	20-p & 60 & 57 & 19 & 183.10 & 0.009 \\ \hline
	25-f & 89 & 14 & 19 & 1016.71 & 0.034 \\ 
	25-p & 77 & 60 & 19 & 227.16 & 0.009 \\ \hline
	30-f & 101 & 14& 19 & 1144.07 & 0.032 \\ 
	30-p & 93 & 62 & 19 & 272.40 & 0.010 \\ \hline
\end{tabular}
\caption{Luxembourg City network}\label{tab:lu4k_results}
\end{center}
\end{subtable}
\caption{Experimental results with 1000 random $s,t$ pairs for each network and multiple maximum budget levels $B$. Results on rows $B-f$ correspond to computing the solution frontier for all budget levels $b\leq B$ while the results on rows $B-s$ correspond to computing the solution for the budget level $b$.}\label{tab:performance_results}
\end{table*}

\begin{figure}
\begin{center}
\includegraphics[clip, trim=0.2cm 0.3cm 0.2cm 0.2cm,scale=0.29]{TexImg/SF_query_dij_B25.pdf}
\includegraphics[clip, trim=1cm 0.3cm 0.2cm 0.2cm,scale=0.29]{TexImg/SF_query_hl_B25.pdf}
\end{center}
\caption{Histogram frontier queries, Dijkstra (left) and HL (right). $B=25$}\label{fig:SF_query}
\end{figure}


\remark{\todo{move figures to Appendix} As explained in Section XXX, creating the hub-labels efficiently requires storing all pairs shortest path distances during the preprocessing stage. In many cases, this can impose a prohibitive memory requirement. However, as can be seen in Figures~\ref{fig:clusters_sf} and~\ref{fig:clusters_lu}, the clustering approach from Section XXX provides a very good approximation of the hubs with even a relatively small number of clusters.}

\begin{figure}
\hfill
\input{TexImg/plot_clusters_sf.tex}
\caption{San Francisco with different clusters}\label{fig:clusters_sf}
\end{figure}

\begin{figure}
\hfill
\input{TexImg/plot_clusters_lu.tex}
\caption{Luxembourg City with different clusters}\label{fig:clusters_lu}
\end{figure}


\subsubsection{Hub sizes and node significance}

Figures \ref{fig:SF_hub_size_map} and \ref{fig:sig_colapse} show the spatial relationships between the node hub sizes and significance (the number of nodes for which this node is a hub) in the San Francisco network. Figure \ref{fig:SF_bwd_size} shows a histogram of these metrics. 

\begin{figure} 
\begin{center}
\includegraphics[clip, trim = 0.1cm 0.3cm 0cm 0cm,scale=0.27]{TexImg/SF_bwd_hub_size.pdf}
\includegraphics[clip, trim = 1.3cm 0.3cm 0cm 0cm,scale=0.27]{TexImg/significance.pdf}
\end{center}
\caption{Size of backward hubs SF (left) and significance(right), frontier, $B=25$}\label{fig:SF_bwd_size}
\end{figure}


\begin{figure}
\begin{center}
\includegraphics[clip, trim=1.7cm 2.2cm 4.7cm 1.7cm,scale=0.8]{TexImg/SF_hub_sizes.pdf}
\includegraphics[clip, trim=13cm 0cm 1.1cm 0cm,scale=0.45]{TexImg/SF_hub_sizes.pdf}
\end{center}
\caption{Map of backward size, $B=25$}\label{fig:SF_hub_size_map}
\end{figure}

\begin{figure} 
\begin{center}
\includegraphics[clip, trim=3.7cm 2.9cm 4.2cm 3cm,scale=0.8]{TexImg/sig_colapse.pdf}
\includegraphics[clip, trim=15cm 1.5cm 0.1cm 0.8cm,scale=0.45]{TexImg/sig_colapse.pdf}
\caption{Significance, $B=25$}\label{fig:sig_colapse}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[scale=0.37]{TexImg/map_LU_sig.png}
\end{center}
\caption{Significance in Luxembourg City, frontier, $B=25$}\label{fig:map_LU} 
\end{figure}
