\respedit{We give below the main notions of HD.
We note that they are all similar and they are interlinked in terms of their properties, see \citep[Section 9]{epsilon_embedding} for several results on this.
We limit the discussion here to highlight the main differences.
\begin{itemize}
\item \citep{hd_journal}: this is the closest to our definition, but we weaken it (make it easier to satisfy).
The difference is that they make the notion of $r$-significant stronger by also calling $r$-significant paths $P$ whose length is $\ell(P)<r$, but can be extended by adding at most one node at each end of $P$ to obtain a path $P'$ with $\ell(P')$.

\item \citep{vc_shortest}: it is also very similar, but technically different in that we define path neighbourhoods $S_r(v)$ as sets of paths (while they use the union of nodes belonging to those paths), hence in our definition there are fewer elements to hit.
On the other hand, they consider paths of lengths between $r$ and $2r$, while we consider paths longer than $r$.
We could also add the restriction of length at most $2r$ without changing any of the results, but at the cost of making the definition even more involved.

\item \citep{highway2010}: it is slightly weaker, in that they look at paths are $r$-significant and contained in a larger ball (of radii $4r$) vs the notion of $r$-significant and within distance $2r$ of a node.
Specifically, for each $v$, they ask for hitting sets of paths $P\subseteq B_{4r}(v)$ such that $\ell(P)>r$.
\end{itemize}
  
 
For $\PS$, a consequence of considering less-restrictive path-neighborhoods is that the highway dimension returned by our definition is smaller than that of \citep{hd_journal}.
In particular, unlike \citep{hd_journal}, the HD of $G$ as per our definition is not an upper bound to the maximum degree $\Delta$ or the doubling constant $\alpha$.
The notion of \citep{highway2010} does not bound the doubling constant.}


With respect to our average HD in \cref{sec:avg_hd}, we note the following.
\begin{remark}
The algorithm in \cref{theo:preproc_avg} makes one call to the VC-dimension solver for each $C_i$.
On the other hand, the algorithm in \citep{hd_journal} calls up to $n$ times the solver for each $C_i$.
Finally, there is an extra $\log n$ factor in the approximation guarantee, but now the value of $h$ can be much smaller.
\end{remark}

We now discuss how our results extend to the definition in \citep{hd_journal}, which we refer to as strong-HD.
The strong-HD defines a path $P$ to be $r$-significant if, by adding at most one hop at each end, we get a shortest path $P'$ longer than $r$.
The path $P'$ is called an $r$-witness for $P$.
Intuitively, a path is significant if it represents a long path.
Observe that, if $P\in\PS$ is such that $\ell(P)>r$, then $P$ is $r$-significant by definition.
We remark also that a path can have many $r$-witnesses.

Finally, the path neighborhood must also be strengthened.
The path $P\in\PS$ belongs to $\Sf_r(v)$ if, $P$ has some $r$-witness $P'$ such that $\dist(v,P')\leq 2r$.
The reverse neighborhood $\Sb_r(v)$ is defined analogously.
With this modified versions of $r$-significant and neighborhood, the notions of LSHS and HD are the same as our previous definitions.

Under the strong-HD, we have  $\Delta\leq h$ and $\alpha\leq h+1$.
Additionally, this definition allows proving results for CH.
Finally, we show that even for the strong-HD, CHD and HD can still be off by a factor of $n$.

\begin{proposition}\label[proposition]{prop:treelike}
For any $h$, we can construct a family of networks such that the sparsity of LSHS is $h$ and that of EPHS is arbitrarily worse than $h$.
\end{proposition}
\begin{proof}
First, we construct an example where the sparsity grows from $h$ to $h^2$.
Consider an $h$-ary tree rooted at $u$ with three levels, i.e., with $1+h+h^2$ nodes.
Now add a node $v$ with $h$ children as in Figure~\ref{fig:treelike}. 
The grandchildren of $v$ are the same as the grandchildren of $u$.

All the edges are bidirectional and have unit cost.
The lengths are as follows: $ux_i$ and $vy_i$ (dashed in Figure~\ref{fig:treelike}) are zero; $uv$ and from $y_i$ to the leafs is one; from $x_i$ to the leafs is three.
It is easy to see that the sparsity of a LSHS is $h+1$.

On the other hand, every leaf $w$ is a $2$-efficient path.
Indeed, it can be extended to $x_iw$ that is the shortest path from $x_i$ to $w$ with constraint 1.
All the leafs are in the ball $B_4(u)$, so the sparsity is at least $h^2$.

\begin{figure}
\centering
\includegraphics[scale=0.5]{TexImg/Treelike.pdf}
\caption{Example where the EPHS is much larger than the LSHS.}\label{fig:treelike}
\end{figure}

The general case works in the same fashion.
We make the sparsity grow to $h^k$ by creating two complete, $k$-level, $h$-ary trees $T$ and $T'$.
Connect the root of $T$ to the root of $T'$ and the leafs of both trees are shared.
Observe that the number of nodes is 
\begin{align*}
n &=[\text{$k$-level $h$-ary tree}] + [\text{$(k-1)$-level $h$-ary tree}]\\
&= ({h^{k+1}-1})/({h-1}) + ({h^k-1})/({h-1}),
\end{align*}
therefore the sparsity is $\Theta(n)$, the worst possible.
\end{proof}